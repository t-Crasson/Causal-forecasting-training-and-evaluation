{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from src.models.model_m_e_theta import m_e_theta_daily\n",
    "from src.data.mimic_iii.real_dataset import MIMIC3RealDatasetCollectionCausal,MIMIC3RealDatasetCollection\n",
    "import yaml\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "from src.models.common import *\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/thomas/mimic/physionet.org/files/mimiciii/CausalTransformer/config/dataset/mimic3_real.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)[\"dataset\"]\n",
    "batch_size=512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot_pred(model,test_loader):\n",
    "    li_outcome = []\n",
    "    li_m = []\n",
    "    li_e = []\n",
    "    li_theta = []\n",
    "    for idx,batch in enumerate(test_loader):\n",
    "        predicted_outputs = []\n",
    "        vitals = batch['vitals'].float()\n",
    "        static_features = batch['static_features'].float()\n",
    "        treatments = batch['current_treatments'].float()\n",
    "        position = torch.arange(batch['vitals'].shape[1])\n",
    "        position = position.repeat(batch['vitals'].shape[0],1,1)\n",
    "        position = torch.permute(position,(0,2,1)).to(batch['vitals'].device)\n",
    "        li_insample_y = batch[\"outputs\"].clone().float()\n",
    "        for i in range(batch['future_past_split'].shape[0]):\n",
    "            vitals[i, int(batch['future_past_split'][i]):] = 0.0\n",
    "            li_insample_y[i,int(batch['future_past_split'][i]):] = 0\n",
    "        static_features = batch['static_features'].float()\n",
    "        treatments = batch['current_treatments'].float()\n",
    "        index = batch[\"future_past_split\"]\n",
    "        temporal = torch.concat([vitals,position,treatments],dim=-1)\n",
    "        treatment = torch.zeros_like(li_insample_y)\n",
    "        for k in range(model.treatment_max):\n",
    "            treatment += temporal[:,:,-1-k].clone().unsqueeze(-1)*(2**k)\n",
    "            for i,tau in enumerate(index):\n",
    "                temporal[i,int(tau):,-1-k] = -1\n",
    "        # Encapsulating inputs\n",
    "        windows = {}\n",
    "        windows[\"insample_y\"] = li_insample_y.to(model.device)\n",
    "        windows[\"multivariate_exog\"] = temporal.to(model.device)\n",
    "        windows[\"stat_exog\"] = static_features.to(model.device)\n",
    "        with torch.no_grad():\n",
    "            m, e, theta = model(windows,index.int())\n",
    "            m = m.cpu()\n",
    "            e = e.cpu()\n",
    "            theta = theta.cpu()\n",
    "        T_reduced = treatment[:,:,0].long().cpu()\n",
    "        T_reduced = F.one_hot(T_reduced, 2**model.treatment_max).float()\n",
    "        if model.is_cdf:\n",
    "            #T_reduced = 1 - torch.cumsum(T_reduced,dim = -1)\n",
    "            T_reduced = torch.cumsum(T_reduced,dim = -1)\n",
    "        shift = torch.matmul((T_reduced-e).unsqueeze(-2), theta.unsqueeze(-1)).squeeze(-1)\n",
    "        outputs_scaled = m + shift\n",
    "        for i in range(batch['vitals'].shape[0]):\n",
    "            split = int(batch['future_past_split'][i])\n",
    "            if split+model.proj_len<61:\n",
    "                predicted_outputs.append(outputs_scaled[i, split :split+model.proj_len, :])\n",
    "                li_m.append(m[i, split :split+model.proj_len, :])\n",
    "                li_theta.append(theta[i, split :split+model.proj_len, :])\n",
    "                li_e.append(e[i, split :split+model.proj_len, :])\n",
    "        predicted_outputs = torch.stack(predicted_outputs)\n",
    "        li_outcome.append(predicted_outputs)\n",
    "    m = torch.stack(li_m)\n",
    "    e = torch.stack(li_e)\n",
    "    theta = torch.stack(li_theta)\n",
    "    outcome = torch.concat(li_outcome)\n",
    "    return outcome, m,e,theta\n",
    "def compute_tau_step_error(model,dataloader):\n",
    "    Y_true = torch.zeros((len(dataloader.dataset),model.proj_len,1))\n",
    "    for i,tau in enumerate(dataloader.dataset.data[\"future_past_split\"]):\n",
    "        tau = int(tau)\n",
    "        Y_true[i] = torch.tensor(dataloader.dataset.data[\"outputs\"][i,tau:tau+model.proj_len])\n",
    "    Y_hat = one_shot_pred(model,dataloader)[0]\n",
    "    return Y_hat.numpy(), Y_true.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3909fc8826424a84ae12a696dd575989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seeds = [10,101,1001,10010,10110]\n",
    "losses_rmse = np.zeros((len(seeds),5))\n",
    "losses_mae = np.zeros((len(seeds),5))\n",
    "for i in tqdm(range(len(seeds))):\n",
    "    dataset_collection = MIMIC3RealDatasetCollection(\"data/processed/all_hourly_data.h5\",min_seq_length=30,max_seq_length=60,\n",
    "                                                     seed=seeds[0],max_number=10000,split = {\"val\":0.15,\"test\":0.15}, projection_horizon=5,autoregressive=True,\n",
    "                                                     outcome_list = config[\"outcome_list\"],\n",
    "                                                     vitals = config[\"vital_list\"],\n",
    "                                                     treatment_list = config[\"treatment_list\"],\n",
    "                                                     static_list = config[\"static_list\"]\n",
    "                                                     )\n",
    "    dataset_collection.process_data_multi()\n",
    "    \n",
    "    dataset = dataset_collection.test_f_multi\n",
    "    test_loader = DataLoader(dataset, batch_size=1024,shuffle=False)\n",
    "\n",
    "    # model_path = \"/home/thomas/fork_causal_transformer/Causal-forecasting-training-and-evaluation/TFT_drop/m_e_density_large_final_correc\"\n",
    "    # model_path = \"/home/thomas/mimic/physionet.org/files/mimiciii/CausalTransformer/TFT/m_e_density_large_final_correc\"\n",
    "    # model_path = \"/home/thomas/mimic/physionet.org/files/mimiciii/CausalTransformer/TFT_drop/theta_density_decay_-5\"\n",
    "    # model_path = \"/home/thomas/mimic/physionet.org/files/mimiciii/CausalTransformer/TFT/m_e_cdf_night\"\n",
    "    # model_path = \"/home/thomas/mimic/physionet.org/files/mimiciii/CausalTransformer/TFT_drop/theta_cdf_0\"\n",
    "    #model_path = \"/home/thomas/fork_causal_transformer/Causal-forecasting-training-and-evaluation/TFT_thomas/theta_density_decay_-5_repro\"\n",
    "    # model_path = \"/home/thomas/fork_causal_transformer/Causal-forecasting-training-and-evaluation/TFT_deterministic/m_e_density_multi_seed\"\n",
    "    # model_path = \"/home/thomas/fork_causal_transformer/Causal-forecasting-training-and-evaluation/TFT_deterministic/theta_density_low_lr\"\n",
    "    model_path = \"/home/thomas/fork_causal_transformer/Causal-forecasting-training-and-evaluation/TFT_deterministic/m_e_density_repro_pipeline\"\n",
    "\n",
    "    file = os.listdir(f\"{model_path}_{i}/checkpoints\")[0]\n",
    "    path = os.path.join(f\"{model_path}_{i}/checkpoints\",file)\n",
    "    #path = \"TFT_drop/theta_cdf_0_0/checkpoints/epoch=0-val_loss=0.48.ckpt\"\n",
    "    \n",
    "    model = m_e_theta_daily.load_from_checkpoint(path,map_location=device).to(device)\n",
    "    model.training_m_e = False\n",
    "    model.eval()\n",
    "\n",
    "    pred,truth = compute_tau_step_error(model,test_loader)\n",
    "    loss = np.sqrt(np.mean((pred-truth)**2,axis=0))*dataset_collection.test_f_multi.scaling_params['output_stds']\n",
    "    losses_rmse[i] = loss.flatten()\n",
    "    loss = np.mean(np.abs(pred-truth),axis=0)*dataset_collection.test_f_multi.scaling_params['output_stds']\n",
    "    losses_mae[i] = loss.flatten()\n",
    "    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.90449958,  9.56974695,  9.87960325, 10.13996955, 10.36254403])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(losses_rmse,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01070116, 0.00456903, 0.00316494, 0.00854463, 0.0132813 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(losses_rmse,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.14121738, 6.7888407 , 7.08935911, 7.33855885, 7.53462494])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(losses_mae,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01371462, 0.0124739 , 0.00643761, 0.02186196, 0.02822455])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(losses_mae,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
