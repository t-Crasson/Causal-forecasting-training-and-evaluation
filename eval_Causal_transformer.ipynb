{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.data.mimic_iii.real_dataset import MIMIC3RealDatasetCollection\n",
    "from src.models.ct import CT\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import yaml\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from hydra.utils import instantiate\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/dataset/mimic3_real.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)[\"dataset\"]\n",
    "with open('config/backbone/ct_hparams/mimic3_real/diastolic_blood_pressure.yaml', 'r') as file:\n",
    "        config_MODEL = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = DictConfig({'model': {'dim_treatments': '???', 'dim_vitals': '???', 'dim_static_features': '???', 'dim_outcomes': '???', 'name': 'CT', 'multi': {'_target_': 'src.models.ct.CT', 'max_seq_length': '65', 'seq_hidden_units': 24, 'br_size': 22, 'fc_hidden_units': 22, 'dropout_rate': 0.2, 'num_layer': 2, 'num_heads': 3, 'max_grad_norm': None, 'batch_size': 64, 'attn_dropout': True, 'disable_cross_attention': False, 'isolate_subnetwork': '_', 'self_positional_encoding': {'absolute': False, 'trainable': True, 'max_relative_position': 30}, 'optimizer': {'optimizer_cls': 'adam', 'learning_rate': 0.0001, 'weight_decay': 0.0, 'lr_scheduler': False}, 'augment_with_masked_vitals': True, 'tune_hparams': False, 'tune_range': 50, 'hparams_grid': None, 'resources_per_trial': None}}, 'dataset': {'val_batch_size': 512, 'treatment_mode': 'multilabel', '_target_': 'src.data.MIMIC3RealDatasetCollection', 'seed': '${exp.seed}', 'name': 'mimic3_real', 'path': 'data/processed/all_hourly_data.h5', 'min_seq_length': 30, 'max_seq_length': 60, 'max_number': 5000, 'projection_horizon': 5, 'split': {'val': 0.15, 'test': 0.15}, 'autoregressive': True, 'treatment_list': ['vaso', 'vent'], 'outcome_list': ['diastolic blood pressure'], 'vital_list': ['heart rate', 'red blood cell count', 'sodium', 'mean blood pressure', 'systemic vascular resistance', 'glucose', 'chloride urine', 'glascow coma scale total', 'hematocrit', 'positive end-expiratory pressure set', 'respiratory rate', 'prothrombin time pt', 'cholesterol', 'hemoglobin', 'creatinine', 'blood urea nitrogen', 'bicarbonate', 'calcium ionized', 'partial pressure of carbon dioxide', 'magnesium', 'anion gap', 'phosphorous', 'venous pvo2', 'platelets', 'calcium urine'], 'static_list': ['gender', 'ethnicity', 'age'], 'drop_first': False}, 'exp': {'seed': 10, 'gpus': [0], 'max_epochs': 1, 'logging': False, 'mlflow_uri': 'http://127.0.0.1:5000', 'unscale_rmse': True, 'percentage_rmse': False, 'alpha': 0.01, 'update_alpha': True, 'alpha_rate': 'exp', 'balancing': 'domain_confusion', 'bce_weight': False, 'weights_ema': True, 'beta': 0.99}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tau_step_error(model, dataset):\n",
    "    Y_true = np.zeros((len(dataset),model.hparams.dataset.projection_horizon,1))\n",
    "    for i,tau in enumerate(dataset.data[\"future_past_split\"]):\n",
    "        tau = int(tau)\n",
    "        Y_true[i] = dataset.data[\"outputs\"][i,tau-1:tau+model.hparams.dataset.projection_horizon-1]\n",
    "    pred_auto_reg = model.get_autoregressive_predictions(dataset)\n",
    "    return pred_auto_reg, Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [10,101,1010,10101,101010]\n",
    "losses_rmse = np.zeros((len(seeds),5))\n",
    "losses_mae = np.zeros((len(seeds),5))\n",
    "for i in range(len(seeds)):\n",
    "    dataset_collection = MIMIC3RealDatasetCollection(\"data/processed/all_hourly_data.h5\",min_seq_length=30,max_seq_length=60,\n",
    "                                                        seed=seeds[i],max_number=10000,split = {\"val\":0.15,\"test\":0.15}, projection_horizon=5,autoregressive=True,\n",
    "                                                        outcome_list = config[\"outcome_list\"],\n",
    "                                                        vitals = config[\"vital_list\"],\n",
    "                                                        treatment_list = config[\"treatment_list\"],\n",
    "                                                        static_list = config[\"static_list\"]\n",
    "                                                        )\n",
    "    dataset_collection.process_data_multi()\n",
    "    args.model.dim_outcomes = dataset_collection.train_f.data['outputs'].shape[-1]\n",
    "    args.model.dim_treatments = dataset_collection.train_f.data['current_treatments'].shape[-1]\n",
    "    args.model.dim_vitals = dataset_collection.train_f.data['vitals'].shape[-1] if dataset_collection.has_vitals else 0\n",
    "    args.model.dim_static_features = dataset_collection.train_f.data['static_features'].shape[-1]\n",
    "    multimodel = instantiate(args.model.multi, args, dataset_collection, _recursive_=False)\n",
    "    multimodel.hparams.exp.weights_ema = False\n",
    "    file = os.listdir(f\"/home/thomas/mimic/physionet.org/files/mimiciii/CausalTransformer/multirun/2024-09-10/02-17-13/{i}/checkpoints/\")[0]\n",
    "    path = os.path.join(f\"/home/thomas/mimic/physionet.org/files/mimiciii/CausalTransformer/multirun/2024-09-10/02-17-13/{i}/checkpoints\",file)\n",
    "    state_dict = torch.load(path)[\"state_dict\"]\n",
    "    multimodel.load_state_dict(state_dict)\n",
    "    multimodel_trainer = Trainer(gpus=eval(str(args.exp.gpus)), max_epochs=args.exp.max_epochs,\n",
    "                                    #terminate_on_nan=True,\n",
    "                                    gradient_clip_val=args.model.multi.max_grad_norm)\n",
    "    multimodel.trainer = multimodel_trainer\n",
    "    multimodel = multimodel.double()\n",
    "    multimodel = multimodel.eval()\n",
    "    \n",
    "    pred,truth = compute_tau_step_error(multimodel,dataset_collection.test_f_multi)\n",
    "    loss = np.sqrt(np.mean((pred-truth)**2,axis=0))*dataset_collection.test_f_multi.scaling_params['output_stds']\n",
    "    losses_rmse[i] = loss.flatten()\n",
    "    loss = np.mean(np.abs(pred-truth),axis=0)*dataset_collection.test_f_multi.scaling_params['output_stds']\n",
    "    losses_mae[i] = loss.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(losses_rmse,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(losses_rmse,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(losses_mae,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(losses_mae,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
